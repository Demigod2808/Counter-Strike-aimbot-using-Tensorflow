{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import mss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import cv2\n",
    "import mss\n",
    "import numpy\n",
    "from PIL import ImageGrab\n",
    "\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'inference_graph'\n",
    "PATH_TO_FROZEN_GRAPH = 'frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = 'mscoco_label_map.pbtxt'\n",
    "NUM_CLASSES = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon = (0,40,800,640)\n",
    "monitor = {\"top\": 40, \"left\": 0, \"width\": 800, \"height\": 640}\n",
    "sct = mss.mss()\n",
    "title = \"FPS benchmark\"\n",
    "display_time = 2\n",
    "fps = 0\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_recordMSS():\n",
    "    global fps, start_time\n",
    "    while True:\n",
    "        # Get raw pixels from the screen, save it to a Numpy array\n",
    "        img = numpy.array(sct.grab(monitor))\n",
    "        # to ger real color we do this:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow(title, cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        fps+=1\n",
    "        TIME = time.time() - start_time\n",
    "        if (TIME) >= display_time :\n",
    "            print(\"FPS: \", fps / (TIME))\n",
    "            fps = 0\n",
    "            start_time = time.time()\n",
    "        # Press \"q\" to quit\n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "       \n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS:  0.04586949641480517\n",
      "FPS:  0.16624173196585307\n",
      "FPS:  0.16435421039560255\n",
      "FPS:  0.16527545607242403\n",
      "FPS:  0.1653481495141959\n"
     ]
    }
   ],
   "source": [
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "    while True:\n",
    "      # Get raw pixels from the screen, save it to a Numpy array\n",
    "      image_np = np.array(sct.grab(monitor))\n",
    "      # to ger real color we do this:\n",
    "      image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "      #image = Image.open(image_path)\n",
    "      # the array based representation of the image will be used later in order to prepare the\n",
    "      # result image with boxes and labels on it.\n",
    "      #image_np = load_image_into_numpy_array(image)\n",
    "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "      # Actual detection.\n",
    "      output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "      # Visualization of the results of a detection.\n",
    "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          output_dict['detection_boxes'],\n",
    "          output_dict['detection_classes'],\n",
    "          output_dict['detection_scores'],\n",
    "          category_index,\n",
    "          instance_masks=output_dict.get('detection_masks'),\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=8)\n",
    "      #plt.figure(figsize=IMAGE_SIZE)\n",
    "      #plt.imshow(image_np)\n",
    "      cv2.imshow(title, cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB))\n",
    "      fps+=1\n",
    "      TIME = time.time() - start_time\n",
    "      if (TIME) >= display_time :\n",
    "        print(\"FPS: \", fps / (TIME))\n",
    "        fps = 0\n",
    "        start_time = time.time()\n",
    "      # Press \"q\" to quit\n",
    "      if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
